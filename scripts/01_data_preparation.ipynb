{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "os. chdir(\"c:\\\\Users\\\\simon\\\\OneDrive\\\\Dokumente\\\\UNILU\\\\3 - HS24\\\\1 MA\\\\business-reports-nlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import texts from txt files in folders into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files_in_folder(folder_path):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                # Extract the immediate parent directory (subfolder) of the file\n",
    "                subfolder_name = os.path.basename(os.path.dirname(full_path))\n",
    "                \n",
    "                data.append({\n",
    "                    'file_name': file,\n",
    "                    'file_path': full_path,\n",
    "                    'source': subfolder_name,\n",
    "                    'content': content.replace('\\n', ' ')\n",
    "                })\n",
    "                \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"texts/txts/tagged/_final\"\n",
    "df = read_text_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split texts according to \\<break\\> characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the new rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over each row in the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Split the content into sentences based on '.', '!', '?'\n",
    "    sentences = re.split(r'<break>', row['content'])\n",
    "    \n",
    "    # Filter out empty strings from the list of sentences\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # Create a new row for each sentence and append it to the list\n",
    "    for sentence in sentences:\n",
    "        new_row = {\n",
    "            'file_name': row['file_name'],\n",
    "            'file_path': row['file_path'],\n",
    "            'source': row['source'],\n",
    "            'content': sentence\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Create a new DataFrame from the list of new rows\n",
    "texts = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(texts['content'].str.count('<MIA>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts[~texts['content'].str.contains('<MIA>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts['year'] = texts['file_name'].str[:4]\n",
    "texts['year'] = texts['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts[texts['content'].str.count(' ') >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts.to_csv('data/paragraphs.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export csv to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('data/paragraphs.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_characters(s):\n",
    "    return ''.join([char for char in s if char.isprintable()])\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in texts.select_dtypes(include=['object']):\n",
    "    texts[col] = texts[col].apply(remove_illegal_characters)\n",
    "\n",
    "texts.to_excel('data/paragraphs.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly create pre-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('data/paragraphs.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = texts.sample(n=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_characters(s):\n",
    "    return ''.join([char for char in s if char.isprintable()])\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in sample.select_dtypes(include=['object']):\n",
    "    sample[col] = sample[col].apply(remove_illegal_characters)\n",
    "\n",
    "sample.to_excel('data/sample.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample another 1250 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_excel('data/sample.xlsx')\n",
    "sample = sample.drop(['index', 'category', 'key', 'note'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'common_column' with the actual name of the column to compare\n",
    "common_column = 'content'\n",
    "\n",
    "# Merge the two DataFrames based on the common column\n",
    "merged_df = texts.merge(sample, on=common_column, how='left', indicator=True)\n",
    "\n",
    "# Keep only the rows that are in df1 but not in df2 based on the indicator column\n",
    "filtered_df1 = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the indicator column\n",
    "filtered_df1 = filtered_df1.drop(columns=['_merge'])\n",
    "\n",
    "# Now, filtered_df1 contains the rows from df1 where the 'common_column' values\n",
    "# are not identical to the values in df2's 'common_column'.\n",
    "\n",
    "new_sample = filtered_df1.sample(n=1250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no identical entries between df1 and df2.\n"
     ]
    }
   ],
   "source": [
    "if sample['content'].isin(new_sample['content']).any():\n",
    "    print(\"There are identical entries between df1 and df2.\")\n",
    "else:\n",
    "    print(\"There are no identical entries between df1 and df2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_characters(s):\n",
    "    if isinstance(s, str):\n",
    "        return ''.join([char for char in s if char.isprintable()])\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in new_sample.select_dtypes(include=['object']):\n",
    "    new_sample[col] = new_sample[col].apply(remove_illegal_characters)\n",
    "\n",
    "new_sample.to_excel('data/sample2.xlsx', index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
