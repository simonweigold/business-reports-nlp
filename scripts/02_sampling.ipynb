{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os. chdir(\"c:\\\\Users\\\\simon\\\\OneDrive\\\\Dokumente\\\\UNILU\\\\3 - HS24\\\\1 MA\\\\business-reports-nlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the first sample (n = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('data/paragraphs.csv', encoding = 'utf-8')\n",
    "\n",
    "sample = texts.sample(n=250)\n",
    "\n",
    "\n",
    "def remove_illegal_characters(s):\n",
    "    return ''.join([char for char in s if char.isprintable()])\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in sample.select_dtypes(include=['object']):\n",
    "    sample[col] = sample[col].apply(remove_illegal_characters)\n",
    "\n",
    "sample.to_excel('data/sample.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the second sample (n = 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_excel('data/sample.xlsx')\n",
    "sample = sample.drop(['index', 'category', 'key', 'note'], axis=1)\n",
    "\n",
    "# Define column which contains the matching entries\n",
    "common_column = 'content'\n",
    "\n",
    "# Merge the two DataFrames based on the common column\n",
    "merged_df = texts.merge(sample, on=common_column, how='left', indicator=True)\n",
    "\n",
    "# Keep only the rows that are in df1 but not in df2 based on the indicator column\n",
    "filtered_df1 = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the indicator column\n",
    "filtered_df1 = filtered_df1.drop(columns=['_merge'])\n",
    "\n",
    "# Now, filtered_df1 contains the rows from df1 where the 'common_column' values\n",
    "# are not identical to the values in df2's 'common_column'.\n",
    "\n",
    "new_sample = filtered_df1.sample(n=1250, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check whether second sampling worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample['content'].isin(new_sample['content']).any():\n",
    "    print(\"There are identical entries between df1 and df2.\")\n",
    "else:\n",
    "    print(\"There are no identical entries between df1 and df2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_characters(s):\n",
    "    if isinstance(s, str):\n",
    "        return ''.join([char for char in s if char.isprintable()])\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in new_sample.select_dtypes(include=['object']):\n",
    "    new_sample[col] = new_sample[col].apply(remove_illegal_characters)\n",
    "\n",
    "new_sample.to_excel('data/sample2.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further split sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find empty rows from sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = pd.read_excel('data/sample2.xlsx')\n",
    "\n",
    "# Filtering rows where 'classification' is NaN\n",
    "empty_classification = sample2[pd.isna(sample2['classification'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split empty rows into df with n = 250 and another df with n = 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 250 cases\n",
    "sample3 = empty_classification.sample(n=250, random_state=42)\n",
    "\n",
    "# Create a DataFrame with the remaining cases\n",
    "sample4 = empty_classification.drop(sample3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save to xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3.to_excel('data/sample3.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "sample4.to_excel('data/sample4.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final sampling\n",
    "into:\n",
    "- training\n",
    "- validation\n",
    "- classifiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "complete = pd.read_csv(\"data/paragraphs.csv\")\n",
    "complete = complete.drop_duplicates(subset='content', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "training = pd.read_excel(\"data/fine-tuning v1/_old/20240101_training.xlsx\")\n",
    "columns_to_merge = ['year', 'file_name', 'source', 'file_path']\n",
    "training = pd.merge(training, complete[columns_to_merge + ['content']], on='content', how='left')\n",
    "training = training.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "validation = pd.read_excel(\"data/fine-tuning v1/validation.xlsx\")\n",
    "validation = validation.rename({'year_x': 'year', 'file_name_x': 'file_name', 'file_path_x': 'file_path', 'source_x': 'source', 'corrected': 'classification'}, axis=1)\n",
    "validation = validation.drop(['index', 'Spalte1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "content_list = pd.concat([training['content'], validation['content']]).tolist()\n",
    "classification = complete[~complete['content'].isin(content_list)]\n",
    "\n",
    "# manually remove rows which contain the following entries within the \"content\" column\n",
    "to_remove = validation[~validation['content'].isin(complete['content'])]['content'].to_list()\n",
    "to_remove.extend(training[~training['content'].isin(complete['content'])]['content'].to_list())\n",
    "to_remove = pd.DataFrame(to_remove, columns=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some final text cleaning and finally exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Cleans the text entries in the specified column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the text column.\n",
    "    column_name (str): The name of the column to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with cleaned text in the specified column.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    # Replace \"- \" with nothing\n",
    "    df_cleaned.loc[:, column_name] = df_cleaned[column_name].str.replace(\"- \", \"\", regex=False)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    df_cleaned.loc[:, column_name] = df_cleaned[column_name].apply(lambda x: re.sub(' +', ' ', x))\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = clean_text_column(training, 'content')\n",
    "validation = clean_text_column(validation, 'content')\n",
    "classification = clean_text_column(classification, 'content')\n",
    "to_remove = clean_text_column(to_remove, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:2540: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "training.to_csv('data/fine-tuning v1/training.csv', index=False)\n",
    "validation.to_csv('data/fine-tuning v1/validation.csv', index=False)\n",
    "classification.to_csv('data/fine-tuning v1/classification.csv', index=False)\n",
    "to_remove.to_csv('data/fine-tuning v1/to_remove.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling for qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of years\n",
    "years = range(2007, 2024)\n",
    "\n",
    "# Define your classifications\n",
    "classifications = [\"Interactions between Payments Players\", \"Data Monetization\", \n",
    "                   \"Growth of Digital Payments\", \"Delivering the Payments Experience\", \n",
    "                   \"Sustainability\", \"Other\"]\n",
    "\n",
    "# Initialize quotas for each combination of classification and year\n",
    "quotas = {(classification, year): 10 for classification in classifications for year in years}\n",
    "\n",
    "# Function to apply the quota sampling\n",
    "def apply_quota_sampling(group, quotas):\n",
    "    classification, year = group.name\n",
    "    quota = quotas.get((classification, year), 0)\n",
    "    return group.sample(n=min(quota, len(group)))\n",
    "\n",
    "# Sample based on quotas\n",
    "sampled_dfs = df.groupby(['classification', 'year']).apply(apply_quota_sampling, quotas=quotas)\n",
    "\n",
    "# Reset index if needed\n",
    "sampled_dfs = sampled_dfs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "Growth of Digital Payments               170\n",
       "Interactions between Payments Players    170\n",
       "Other                                    167\n",
       "Data Monetization                        161\n",
       "Sustainability                           139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dfs['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "capgemini    392\n",
       "mckinsey     242\n",
       "bcg           91\n",
       "bain          43\n",
       "accenture     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dfs['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_characters(s):\n",
    "    if isinstance(s, str):\n",
    "        return ''.join([char for char in s if char.isprintable()])\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Apply the function to each string column\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    sampled_dfs[col] = sampled_dfs[col].apply(remove_illegal_characters)\n",
    "\n",
    "sampled_dfs.to_excel('data/qualitative/quota-sampling.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
